{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eea852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "from scipy.stats import norm\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from scipy import stats\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2bb0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gen_fbm_nn_model as fbm_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cc4e52",
   "metadata": {},
   "source": [
    "### Displacements and exponent prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f57ec236",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_displacement(x_data, y_data, z_data, start_index=0):\n",
    "\n",
    "    disps = np.sqrt(np.power(x_data-x_data[0],2) + np.power(y_data-y_data[0],2) + np.power(z_data-z_data[0],2))\n",
    "    \n",
    "    return disps \n",
    "\n",
    "def estimate_hurst(disps, time, window):\n",
    "    \n",
    "    h = np.array([])\n",
    "    ht = np.array([])\n",
    "    for i in range(int(window/2), len(disps)-int(1+window/2)):\n",
    "        #sample of <window> points to calculate hurst exponent for\n",
    "        inx = disps[(i-int(window/2)):(i+int(1+window/2))]\n",
    "        #apply differencing and normalization on the data\n",
    "        inx = np.array([(inx[1:]-inx[0:-1])/(np.amax(inx)-np.amin(inx))])\n",
    "        test = model.predict(inx,verbose=0)\n",
    "        h=np.append(h,test[0][0])\n",
    "        ht = np.append(ht,time[i])\n",
    "        \n",
    "    return h,ht"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bf409f",
   "metadata": {},
   "source": [
    "### Downsampling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1988ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(data_input, down_int, start_index=0):\n",
    "    \n",
    "    data_out = data_input.iloc[start_index::down_int]\n",
    "    return data_out\n",
    "\n",
    "\n",
    "def dsample_est_hurst(data_in, ds_rate, window):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_in: pandas dataframe\n",
    "        ds_rate: int, downsampling step size\n",
    "    Returns:\n",
    "        h_arr: 2D np array\n",
    "        ht_arr: 2D np array\n",
    "    \"\"\"\n",
    "    \n",
    "    h_arr = np.empty((ds_rate,(len(data_in)//ds_rate)-(window+1)))\n",
    "    ht_arr = np.empty((ds_rate,(len(data_in)//ds_rate)-(window+1)))\n",
    "    \n",
    "    for i in np.arange(ds_rate):\n",
    "        \n",
    "        downsampled_data = downsample(data_in, ds_rate, i)\n",
    "        x = np.array(downsampled_data['Position X'])\n",
    "        y = np.array(downsampled_data['Position Y'])\n",
    "        z = np.array(downsampled_data['Position Z'])\n",
    "        t = np.array(downsampled_data['Absolute Time'])\n",
    "        displacements = find_displacement(x,y,z)\n",
    "        h,ht = estimate_hurst(displacements, t, window)\n",
    "        \n",
    "        if len(h)>np.shape(h_arr)[1]:\n",
    "            h=h[:-1]\n",
    "            ht=ht[:-1]\n",
    "            \n",
    "        h_arr[i] = h\n",
    "        ht_arr[i] = ht\n",
    "        \n",
    "    return h_arr,ht_arr\n",
    "\n",
    "\n",
    "#def average_hurst(h_arr, ht_arr):\n",
    "#    \"\"\"\n",
    "#    \"\"\"\n",
    "#    h_average_arr = np.mean(h_arr, axis=0)\n",
    "#    ht_average_arr = np.mean(ht_arr, axis=0)\n",
    "#    \n",
    "#    return h_average_arr, ht_average_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "471ac10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data_in, max_step_size, window, restriction=-1):\n",
    "    \"\"\"\n",
    "    Only keeps data for tracks that are long enough for hurst exponent estimation at a given downsampling step size.\n",
    "    Args: \n",
    "        data_in: pandas dataframe, original data\n",
    "        max_step_size: int, maximum downsampling step size\n",
    "        window: int, size of rolling window for hurst component estimation\n",
    "    Returns:\n",
    "        filtered_data: pandas dataframe\n",
    "    \"\"\"\n",
    "    tracks_to_keep = data_in.TrackID.value_counts().loc[lambda x: (x//max_step_size) > (window+1)].reset_index()['index']\n",
    "    if restriction<len(tracks_to_keep):\n",
    "        filtered_data = data_in[data_in['TrackID'].isin(tracks_to_keep[:restriction])]\n",
    "    else:\n",
    "        filtered_data = data_in[data_in['TrackID'].isin(tracks_to_keep)]\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8947f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_h_values(filtered_data, step_size, window, restriction):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        filtered_data: pandas dataframe\n",
    "    Returns 1D array of (mean) hurst exponent values for a given step size.\n",
    "    \"\"\"\n",
    "    track_id_values = np.unique(filtered_data['TrackID'])\n",
    "    \n",
    "    h = np.array([])\n",
    "    for tid in track_id_values:\n",
    "        track_data = filtered_data[filtered_data['TrackID']==tid]\n",
    "        h_arr, ht_arr = dsample_est_hurst(track_data, step_size, window)  \n",
    "        # h_av_arr, ht_av_arr = average_hurst(h_arr, ht_arr)  \n",
    "        h = np.append(h, np.ravel(h_arr))\n",
    "        \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "637c3527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_h_dict(filtered_data, step_sizes, window, restriction):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    h_dict = {}\n",
    "    \n",
    "    for i, s in enumerate(step_sizes):\n",
    "        h_arr = get_h_values(filtered_data, s, window, restriction)\n",
    "        h_dict[\"{}\".format(s)] = h_arr.tolist()\n",
    "        \n",
    "    return h_dict\n",
    "\n",
    "def get_hist_h(h_dictionary, nbins):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    keys_list = list(h_dictionary)\n",
    "    \n",
    "    counts_all = np.empty((len(keys_list), nbins))\n",
    "    bins_all = np.empty((len(keys_list), nbins+1))\n",
    "    \n",
    "    for i,key in enumerate(keys_list):\n",
    "        counts, bins = np.histogram(h_dictionary[key], nbins, density=True)  # normalised so area under histogram is 1\n",
    "        counts_all[i] = counts\n",
    "        bins_all[i] = bins\n",
    "    \n",
    "    return counts_all, bins_all\n",
    "\n",
    "def save_h_data(h_data, file_name, window, step_sizes, restriction):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    with open('h_dict_'+'w{}_'.format(window)+'s{}_'.format(max(step_sizes))+'r{}_'.format(restriction)+file_name, 'w') as file:\n",
    "        file.write(json.dumps(h_data))\n",
    "        \n",
    "def get_dict_from_file(file_name, window, step_sizes, restriction,path='h_dict_data/'):\n",
    "    \"\"\"\n",
    "    Reads in dictionary of H values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path+'h_dict_'+'w{}_'.format(window)+'s{}_'.format(max(step_sizes))+'r{}_'.format(restriction)+file_name, 'r') as file:\n",
    "            h_dict = file.read()\n",
    "    except FileNotFoundError:\n",
    "        with open(path+'h_dict_'+'w{}_'.format(window)+'s{}_'.format(max(step_sizes))+'r{}_'.format(restriction)+file_name+'.txt', 'r') as file:\n",
    "            h_dict = file.read()\n",
    "        \n",
    "    return json.loads(h_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1c3f91",
   "metadata": {},
   "source": [
    "### Number of tracks available for given window size and step sizes 1, 2, ..., 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42312d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_tracks(filenames, window, step_sizes=np.array([1,2,3,4,5,6,7,8,9,10]), pandas_df=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ntracks_dict = {}\n",
    "    \n",
    "    for i, file in enumerate(filenames):\n",
    "        data = pd.read_csv('haemocyte_tracking_data/'+file+'.csv')\n",
    "        ntracks = np.empty((len(step_sizes)+1))\n",
    "        ntracks[0] = len(np.unique(data['TrackID']))  # number of tracks in original data (independent of window, step size)\n",
    "        for j, s in enumerate(step_sizes):\n",
    "            filtered_data = filter_data(data, s, window)\n",
    "            ntracks[j+1] = len(np.unique(filtered_data['TrackID']))  # number of tracks in filtered data\n",
    "        ntracks_dict[file] = ntracks.tolist()\n",
    "    \n",
    "    if not pandas_df:\n",
    "        return ntracks_dict\n",
    "    \n",
    "    else:\n",
    "        column_labels = np.array(['original'])\n",
    "        column_labels = np.append(column_labels, step_sizes.astype(str))\n",
    "        df = pd.DataFrame.from_dict(ntracks_dict, orient='index', columns=column_labels)\n",
    "        return df.apply(pd.to_numeric, downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce0208cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for a window size of 10:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Control_frame001-200</th>\n",
       "      <td>1806</td>\n",
       "      <td>1789</td>\n",
       "      <td>1208</td>\n",
       "      <td>765</td>\n",
       "      <td>517</td>\n",
       "      <td>348</td>\n",
       "      <td>246</td>\n",
       "      <td>171</td>\n",
       "      <td>135</td>\n",
       "      <td>99</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Control_frame200-400</th>\n",
       "      <td>1468</td>\n",
       "      <td>1466</td>\n",
       "      <td>1149</td>\n",
       "      <td>819</td>\n",
       "      <td>621</td>\n",
       "      <td>448</td>\n",
       "      <td>332</td>\n",
       "      <td>252</td>\n",
       "      <td>192</td>\n",
       "      <td>146</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Control_frame400-600</th>\n",
       "      <td>2172</td>\n",
       "      <td>2170</td>\n",
       "      <td>1815</td>\n",
       "      <td>1308</td>\n",
       "      <td>1000</td>\n",
       "      <td>728</td>\n",
       "      <td>563</td>\n",
       "      <td>433</td>\n",
       "      <td>364</td>\n",
       "      <td>292</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Control_frame600-800</th>\n",
       "      <td>2117</td>\n",
       "      <td>2111</td>\n",
       "      <td>1833</td>\n",
       "      <td>1344</td>\n",
       "      <td>992</td>\n",
       "      <td>765</td>\n",
       "      <td>615</td>\n",
       "      <td>510</td>\n",
       "      <td>415</td>\n",
       "      <td>347</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Control_frame800-1000</th>\n",
       "      <td>1725</td>\n",
       "      <td>1724</td>\n",
       "      <td>1558</td>\n",
       "      <td>1220</td>\n",
       "      <td>945</td>\n",
       "      <td>749</td>\n",
       "      <td>602</td>\n",
       "      <td>514</td>\n",
       "      <td>430</td>\n",
       "      <td>342</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Control_frame1000-1200</th>\n",
       "      <td>1624</td>\n",
       "      <td>1623</td>\n",
       "      <td>1469</td>\n",
       "      <td>1217</td>\n",
       "      <td>944</td>\n",
       "      <td>740</td>\n",
       "      <td>596</td>\n",
       "      <td>477</td>\n",
       "      <td>395</td>\n",
       "      <td>332</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LanB1_frame001-200</th>\n",
       "      <td>4793</td>\n",
       "      <td>2080</td>\n",
       "      <td>1124</td>\n",
       "      <td>665</td>\n",
       "      <td>416</td>\n",
       "      <td>280</td>\n",
       "      <td>210</td>\n",
       "      <td>144</td>\n",
       "      <td>108</td>\n",
       "      <td>83</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LanB1_frame200-400</th>\n",
       "      <td>7239</td>\n",
       "      <td>2818</td>\n",
       "      <td>1549</td>\n",
       "      <td>994</td>\n",
       "      <td>671</td>\n",
       "      <td>469</td>\n",
       "      <td>350</td>\n",
       "      <td>278</td>\n",
       "      <td>223</td>\n",
       "      <td>174</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LanB1_frame400-600</th>\n",
       "      <td>3091</td>\n",
       "      <td>1439</td>\n",
       "      <td>914</td>\n",
       "      <td>660</td>\n",
       "      <td>508</td>\n",
       "      <td>415</td>\n",
       "      <td>336</td>\n",
       "      <td>284</td>\n",
       "      <td>225</td>\n",
       "      <td>189</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LanB1_frame600-800</th>\n",
       "      <td>5046</td>\n",
       "      <td>2247</td>\n",
       "      <td>1419</td>\n",
       "      <td>1050</td>\n",
       "      <td>793</td>\n",
       "      <td>643</td>\n",
       "      <td>546</td>\n",
       "      <td>461</td>\n",
       "      <td>393</td>\n",
       "      <td>336</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LanB1_frame800-1000</th>\n",
       "      <td>6418</td>\n",
       "      <td>2647</td>\n",
       "      <td>1619</td>\n",
       "      <td>1161</td>\n",
       "      <td>896</td>\n",
       "      <td>722</td>\n",
       "      <td>602</td>\n",
       "      <td>502</td>\n",
       "      <td>418</td>\n",
       "      <td>368</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LanB1_frame1000-1200</th>\n",
       "      <td>4527</td>\n",
       "      <td>1917</td>\n",
       "      <td>1232</td>\n",
       "      <td>927</td>\n",
       "      <td>725</td>\n",
       "      <td>593</td>\n",
       "      <td>496</td>\n",
       "      <td>430</td>\n",
       "      <td>375</td>\n",
       "      <td>335</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defLanB1_300817_frame200-400</th>\n",
       "      <td>2445</td>\n",
       "      <td>2432</td>\n",
       "      <td>1718</td>\n",
       "      <td>1130</td>\n",
       "      <td>742</td>\n",
       "      <td>541</td>\n",
       "      <td>399</td>\n",
       "      <td>315</td>\n",
       "      <td>255</td>\n",
       "      <td>200</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defLanB1_300817_frame400-600</th>\n",
       "      <td>2015</td>\n",
       "      <td>2008</td>\n",
       "      <td>1637</td>\n",
       "      <td>1190</td>\n",
       "      <td>881</td>\n",
       "      <td>676</td>\n",
       "      <td>556</td>\n",
       "      <td>444</td>\n",
       "      <td>366</td>\n",
       "      <td>307</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              original     1     2     3     4    5    6    7  \\\n",
       "Control_frame001-200              1806  1789  1208   765   517  348  246  171   \n",
       "Control_frame200-400              1468  1466  1149   819   621  448  332  252   \n",
       "Control_frame400-600              2172  2170  1815  1308  1000  728  563  433   \n",
       "Control_frame600-800              2117  2111  1833  1344   992  765  615  510   \n",
       "Control_frame800-1000             1725  1724  1558  1220   945  749  602  514   \n",
       "Control_frame1000-1200            1624  1623  1469  1217   944  740  596  477   \n",
       "LanB1_frame001-200                4793  2080  1124   665   416  280  210  144   \n",
       "LanB1_frame200-400                7239  2818  1549   994   671  469  350  278   \n",
       "LanB1_frame400-600                3091  1439   914   660   508  415  336  284   \n",
       "LanB1_frame600-800                5046  2247  1419  1050   793  643  546  461   \n",
       "LanB1_frame800-1000               6418  2647  1619  1161   896  722  602  502   \n",
       "LanB1_frame1000-1200              4527  1917  1232   927   725  593  496  430   \n",
       "defLanB1_300817_frame200-400      2445  2432  1718  1130   742  541  399  315   \n",
       "defLanB1_300817_frame400-600      2015  2008  1637  1190   881  676  556  444   \n",
       "\n",
       "                                8    9   10  \n",
       "Control_frame001-200          135   99   77  \n",
       "Control_frame200-400          192  146  116  \n",
       "Control_frame400-600          364  292  248  \n",
       "Control_frame600-800          415  347  288  \n",
       "Control_frame800-1000         430  342  307  \n",
       "Control_frame1000-1200        395  332  282  \n",
       "LanB1_frame001-200            108   83   72  \n",
       "LanB1_frame200-400            223  174  140  \n",
       "LanB1_frame400-600            225  189  160  \n",
       "LanB1_frame600-800            393  336  297  \n",
       "LanB1_frame800-1000           418  368  329  \n",
       "LanB1_frame1000-1200          375  335  293  \n",
       "defLanB1_300817_frame200-400  255  200  158  \n",
       "defLanB1_300817_frame400-600  366  307  273  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 10\n",
    "\n",
    "filenames = np.array(['Control_frame001-200',\n",
    "                      'Control_frame200-400',\n",
    "                      'Control_frame400-600',\n",
    "                      'Control_frame600-800',\n",
    "                      'Control_frame800-1000',\n",
    "                      'Control_frame1000-1200',\n",
    "                      'LanB1_frame001-200',\n",
    "                      'LanB1_frame200-400',\n",
    "                      'LanB1_frame400-600',\n",
    "                      'LanB1_frame600-800',\n",
    "                      'LanB1_frame800-1000',\n",
    "                      'LanB1_frame1000-1200',\n",
    "                      'defLanB1_300817_frame200-400',\n",
    "                      'defLanB1_300817_frame400-600'])\n",
    "\n",
    "print('for a window size of {}:'.format(window))\n",
    "number_of_tracks(filenames, window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb1d9f2",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a3813de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#load neural network model\n",
    "def load_nn_model(window_size,n_samples=100,n_epochs=100):\n",
    "\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(\"model3dense_n{}.h5\".format(window_size))\n",
    "    except OSError:\n",
    "        fbm_nn.__main__(n_samples,window_size,n_epochs)\n",
    "        model = tf.keras.models.load_model(\"model3dense_n{}.h5\".format(window_size))\n",
    "    return model \n",
    "\n",
    "model = load_nn_model(window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dac03b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened file Control_frame800-1000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-2e42c6b3f370>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'haemocyte_tracking_data/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mfiltered_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestriction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mh_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_h_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestriction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0msave_h_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestriction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-277576386368>\u001b[0m in \u001b[0;36mget_h_dict\u001b[1;34m(filtered_data, step_sizes, window, restriction)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mh_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_h_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestriction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mh_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-1977a45c5aee>\u001b[0m in \u001b[0;36mget_h_values\u001b[1;34m(filtered_data, step_size, window, restriction)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrack_id_values\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mtrack_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfiltered_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TrackID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mtid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mh_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mht_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdsample_est_hurst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;31m# h_av_arr, ht_av_arr = average_hurst(h_arr, ht_arr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-65cecb00d7d7>\u001b[0m in \u001b[0;36mdsample_est_hurst\u001b[1;34m(data_in, ds_rate, window)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdownsampled_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Absolute Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mdisplacements\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_displacement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mht\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimate_hurst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisplacements\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-60e231652378>\u001b[0m in \u001b[0;36mestimate_hurst\u001b[1;34m(disps, time, window)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m#apply differencing and normalization on the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0minx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0minx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mht\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mht\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "step_sizes = [1,2,3,4,5,6,7,8]\n",
    "restriction = 30\n",
    "\n",
    "#filenames = ['Control_frame200-400', 'LanB1_frame200-400']\n",
    "\n",
    "# iterate over data files and save H dictionary \n",
    "for i, file in enumerate(filenames[4:]):\n",
    "    print('opened file {}'.format(file))\n",
    "    data = pd.read_csv('haemocyte_tracking_data/' + file + '.csv')\n",
    "    filtered_data = filter_data(data, max(step_sizes), window, restriction)\n",
    "    h_dict = get_h_dict(filtered_data, step_sizes, window, restriction)\n",
    "    save_h_data(h_dict, file, window, step_sizes, restriction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6769e12",
   "metadata": {},
   "source": [
    "## Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16b57c90",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-54-d39c11e44a24>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-54-d39c11e44a24>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#### OLD h down sampling + averaging \n",
    "\"\"\"\n",
    "def get_hht_avg_dict(data_in, step_sizes):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    h_av_dict = {}\n",
    "    #ht_av_dict = {}\n",
    "    \n",
    "    for i, s in enumerate(step_sizes):\n",
    "        h_arr, ht_arr = dsample_est_hurst(data_in, s)\n",
    "        h_av_arr, ht_av_arr = average_hurst(h_arr, ht_arr)\n",
    "    \n",
    "        h_av_dict[\"{}\".format(s)] = h_av_arr.tolist()\n",
    "     #   ht_av_dict[\"{}\".format(s)] = ht_av_arr.tolist()\n",
    "        \n",
    "    return h_av_dict#, ht_av_dict\n",
    "    \n",
    "\n",
    "def save_hht_data(h_avg_data,ht_avg_data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    with open('h_avg_file.txt', 'w') as h_avg_file:\n",
    "        h_avg_file.write(json.dumps(h_avg_data))\n",
    "        \n",
    "    with open('ht_avg_file.txt', 'w') as ht_avg_file:\n",
    "        ht_avg_file.write(json.dumps(ht_avg_data))\n",
    "\"\"\"\n",
    "#### 2 and 3D Plotting -- moved to haemocyte_plot\n",
    "### frist block is really old \n",
    "        \n",
    "\"\"\"\"    \n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "cmap = plt.cm.plasma\n",
    "\n",
    "yticks = np.array(step_sizes)\n",
    "\n",
    "for i, s in enumerate(step_sizes):\n",
    "    ytick = yticks[i]\n",
    "    normalised_counts = hist[0][i]\n",
    "    bins = hist[1][i]\n",
    "    xcenter = np.convolve(bins, np.ones(2), \"valid\")/2\n",
    "    xwidth = np.diff(bins)\n",
    "    ax.bar(left=xcenter, height=normalised_counts, width=xwidth, zs=ytick,\n",
    "           zdir=\"y\", color=cmap(i/len(yticks)), alpha=0.6, edgecolor=\"grey\", linewidth=0.3)\n",
    "    \n",
    "ax.set_xlabel(\"H\")\n",
    "ax.set_ylabel(\"downsampling step size\")\n",
    "ax.set_zlabel(\"P(H)\")\n",
    "\n",
    "ax.set_yticks(yticks)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def plot_3d(h_dict,n_bins):\n",
    "    \n",
    "    %matplotlib notebook\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "    cmap = plt.cm.plasma\n",
    "    \n",
    "    steps = [int(s) for s in list(h_dict)]\n",
    "    yticks = np.array(steps)\n",
    "    \n",
    "    norm_counts, bins = get_hist_h(h_dict,n_bins)\n",
    "\n",
    "    for i,_ in enumerate(steps):\n",
    "        ytick = yticks[i]\n",
    "        temp_counts = norm_counts[i]\n",
    "        temp_bins = bins[i]\n",
    "        xcenter = np.convolve(temp_bins, np.ones(2), \"valid\")/2\n",
    "        xwidth = np.diff(temp_bins)\n",
    "        ax.bar(left=xcenter, height=temp_counts, width=xwidth, zs=ytick,\n",
    "               zdir=\"y\", color=cmap(i/len(yticks)), alpha=0.6, edgecolor=\"grey\", linewidth=0.3)\n",
    "       \n",
    "\n",
    "    ax.set_xlabel(\"H\")\n",
    "    ax.set_ylabel(\"downsampling step size\")\n",
    "    ax.set_zlabel(\"P(H)\")\n",
    "\n",
    "    ax.set_yticks(yticks)\n",
    "    plt.show()\n",
    "    \n",
    "    return norm_counts,bins\n",
    "\n",
    "def plot_hist_2D(data, step_sizes, nbins, window):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    track_id_values = np.unique(data['TrackID'])\n",
    "    \n",
    "    # plot histogram for each downsampling step size\n",
    "    for s in step_sizes:\n",
    "        # compute H values for each track and put them all in one array\n",
    "        h = np.array([])\n",
    "        for tid in track_id_values:\n",
    "            track_data = data[data['TrackID']==tid]\n",
    "            h_arr, ht_arr = dsample_est_hurst(track_data, s, window)  \n",
    "            # h_av_arr, ht_av_arr = average_hurst(h_arr, ht_arr)  \n",
    "            h = np.append(h, np.ravel(h_arr))\n",
    "        plt.hist(h, nbins, density=True, label='step size = {}'.format(s))  \n",
    "        # density=True for normalisation so that area under histogram integrates to 1\n",
    "    plt.legend()\n",
    "    plt.xlabel('H')\n",
    "    plt.ylabel('p(H)')\n",
    "    plt.show()\n",
    "    \n",
    "step_sizes = [1,2,3,4,5,6,7,8]\n",
    "h_dict_temp = get_dict_from_file('LanB1_frame1000-1200',10,step_sizes,30)\n",
    "norm_counts,bins = plot_3d(h_dict_temp,25)\n",
    "        \n",
    "\"\"\"\n",
    "#### hurst vs time plot -- Not sure if this has been moved anywhere else???\n",
    "\"\"\"\n",
    "def plot_downsampled_hurst(h_arr, ht_arr):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    h_av_arr, ht_av_arr = average_hurst(h_arr, ht_arr)\n",
    "    \n",
    "    for i in np.arange(len(h_arr)):\n",
    "        plt.plot(ht_arr[i], h_arr[i], alpha=0.5)\n",
    "    plt.plot(ht_av_arr, h_av_arr, label='mean H', color='k')\n",
    "    plt.axhline(0.5, c='r')\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('H')\n",
    "    plt.title('Downsampled data, step size {}'.format(len(h_arr)))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f96e7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# first of all, let\\'s confirm the optimal number of components\\ndef optimum_components(data,n_max,plot=0):\\n    bics = []\\n    min_bic = 0\\n    counter=1\\n    for i in range (n_max-1): # test the AIC/BIC metric between 1 and 10 components\\n        gmm = GMM(n_components = counter, max_iter=1000, random_state=0, covariance_type = \\'full\\')\\n        labels = gmm.fit(data).predict(data)\\n        bic = gmm.bic(data)\\n        bics.append(bic)\\n        if bic < min_bic or min_bic == 0:\\n            min_bic = bic\\n            opt_bic = counter\\n        counter +=1\\n    \\n    if plot==1:    \\n        fig,ax = plt.subplots(figsize=(10, 4))\\n        # Plot 1\\n        plt.plot(np.arange(1,n_max), bics, \\'o-\\', lw=3, c=\\'black\\', label=\\'BIC\\')\\n        plt.legend(frameon=False, fontsize=15)\\n        plt.xlabel(\\'Number of components\\', fontsize=12)\\n        plt.ylabel(\\'Bayesian Information criterion\\', fontsize=12)\\n        plt.xticks(np.arange(0,n_max, 2))\\n        plt.title(\\'Opt. components = \\'+str(opt_bic), fontsize=20)\\n        plt.show()\\n\\n        \\n    return opt_bic,bics\\n\\ndata_temp = np.concatenate((np.random.normal(5, 1, 1000), np.random.normal(10, 2, 1000),np.random.normal(15, 3, 1000)))\\ndata_temp = data_temp.reshape(-1, 1)   #hist[1][1].reshape(-1,1)\\nn_optimum,bic_vals = optimum_components(data_temp,10,plot=1)\\n\\nfig,ax = plt.subplots()\\nplt.hist(data_temp,100)\\nplt.show()\\n\\n# create GMM model object\\ngmm = GMM(n_components = n_optimum, max_iter=1000, random_state=10, covariance_type = \\'full\\')\\n\\n# find useful parameters\\nmean = gmm.fit(data_temp).means_  \\ncovs  = gmm.fit(data_temp).covariances_\\nweights = gmm.fit(data_temp).weights_\\n\\nx_axis = np.arange(-50, 50, 0.1)\\n\\n# create necessary things to plot\\ng1 = norm.pdf(x_axis, float(mean[0][0]), np.sqrt(float(covs[0][0][0])))*weights[0] # 1st gaussian\\ng2 = norm.pdf(x_axis, float(mean[1][0]), np.sqrt(float(covs[0][0][0])))*weights[1] # 1st gaussian\\ng3 = norm.pdf(x_axis, float(mean[2][0]), np.sqrt(float(covs[0][0][0])))*weights[2] # 1st gaussian\\n\\nfig,ax = plt.subplots(figsize=(9,8))\\n# Plot 2\\nplt.hist(data_temp, density=True, color=\\'black\\',bins=100)\\nplt.plot(x_axis, g1, c=\\'r\\')\\nplt.plot(x_axis, g2, c=\\'g\\')\\nplt.plot(x_axis, g3, c=\\'b\\')\\nplt.xlabel(r\"X\", fontsize=20)\\nplt.ylabel(r\"Density\", fontsize=20)\\n\\nplt.show()\\n\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####GMM code old\n",
    "\n",
    "\"\"\"\n",
    "# first of all, let's confirm the optimal number of components\n",
    "def optimum_components(data,n_max,plot=0):\n",
    "    bics = []\n",
    "    min_bic = 0\n",
    "    counter=1\n",
    "    for i in range (n_max-1): # test the AIC/BIC metric between 1 and 10 components\n",
    "        gmm = GMM(n_components = counter, max_iter=1000, random_state=0, covariance_type = 'full')\n",
    "        labels = gmm.fit(data).predict(data)\n",
    "        bic = gmm.bic(data)\n",
    "        bics.append(bic)\n",
    "        if bic < min_bic or min_bic == 0:\n",
    "            min_bic = bic\n",
    "            opt_bic = counter\n",
    "        counter +=1\n",
    "    \n",
    "    if plot==1:    \n",
    "        fig,ax = plt.subplots(figsize=(10, 4))\n",
    "        # Plot 1\n",
    "        plt.plot(np.arange(1,n_max), bics, 'o-', lw=3, c='black', label='BIC')\n",
    "        plt.legend(frameon=False, fontsize=15)\n",
    "        plt.xlabel('Number of components', fontsize=12)\n",
    "        plt.ylabel('Bayesian Information criterion', fontsize=12)\n",
    "        plt.xticks(np.arange(0,n_max, 2))\n",
    "        plt.title('Opt. components = '+str(opt_bic), fontsize=20)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    return opt_bic,bics\n",
    "\n",
    "data_temp = np.concatenate((np.random.normal(5, 1, 1000), np.random.normal(10, 2, 1000),np.random.normal(15, 3, 1000)))\n",
    "data_temp = data_temp.reshape(-1, 1)   #hist[1][1].reshape(-1,1)\n",
    "n_optimum,bic_vals = optimum_components(data_temp,10,plot=1)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "plt.hist(data_temp,100)\n",
    "plt.show()\n",
    "\n",
    "# create GMM model object\n",
    "gmm = GMM(n_components = n_optimum, max_iter=1000, random_state=10, covariance_type = 'full')\n",
    "\n",
    "# find useful parameters\n",
    "mean = gmm.fit(data_temp).means_  \n",
    "covs  = gmm.fit(data_temp).covariances_\n",
    "weights = gmm.fit(data_temp).weights_\n",
    "\n",
    "x_axis = np.arange(-50, 50, 0.1)\n",
    "\n",
    "# create necessary things to plot\n",
    "g1 = norm.pdf(x_axis, float(mean[0][0]), np.sqrt(float(covs[0][0][0])))*weights[0] # 1st gaussian\n",
    "g2 = norm.pdf(x_axis, float(mean[1][0]), np.sqrt(float(covs[0][0][0])))*weights[1] # 1st gaussian\n",
    "g3 = norm.pdf(x_axis, float(mean[2][0]), np.sqrt(float(covs[0][0][0])))*weights[2] # 1st gaussian\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(9,8))\n",
    "# Plot 2\n",
    "plt.hist(data_temp, density=True, color='black',bins=100)\n",
    "plt.plot(x_axis, g1, c='r')\n",
    "plt.plot(x_axis, g2, c='g')\n",
    "plt.plot(x_axis, g3, c='b')\n",
    "plt.xlabel(r\"X\", fontsize=20)\n",
    "plt.ylabel(r\"Density\", fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ae21a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
